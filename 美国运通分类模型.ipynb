{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e12889",
   "metadata": {},
   "source": [
    "# 美国运通-信用卡逾期风险预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd0848",
   "metadata": {},
   "source": [
    "#### 写在前言\n",
    "\n",
    "该代码文件记录了我在参加这一次kaggle竞赛的代码历程，当然最终效果也只进入20%，无法和kaggle金牌大佬比较，但整体代码也可以给初次参加kaggle竞赛或是想从凡人角度了解该比赛的小伙伴们一些参考。觉得不对的欢迎大家指正批评，我也会一直保持学习的态度去努力。金牌大佬代码链接我会附在说明文档中，供学有余力的同学浏xin览shang。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f162005",
   "metadata": {},
   "source": [
    "### 下载可用包"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05d4c16",
   "metadata": {},
   "source": [
    "由于我租用了外部服务器（本地服务器完全跑不动），这几个包是重要的建模工具，需要自行手动下载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab1d1c1-8189-45dc-8368-2fa8fdfa1f43",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting xgboost\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e4/ed/8e2a7ae4e856f4887afc0beee897088ed8dbbc1b19b0f49971019939452a/xgboost-1.6.1-py3-none-manylinux2014_x86_64.whl (192.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 192.9 MB 74.0 MB/s eta 0:00:01   |▏                               | 757 kB 27.9 MB/s eta 0:00:07     |████████▋                       | 51.8 MB 27.9 MB/s eta 0:00:06     |█████████                       | 54.5 MB 27.9 MB/s eta 0:00:05     |██████████▍                     | 62.6 MB 52.9 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: scipy in /environment/miniconda3/lib/python3.7/site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in /environment/miniconda3/lib/python3.7/site-packages (from xgboost) (1.21.4)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install xgboost\n",
    "#pip install lightgbm\n",
    "#pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d99af52",
   "metadata": {},
   "source": [
    "### 1. 调包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9576b41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T08:54:02.903727Z",
     "start_time": "2022-08-08T08:54:02.061151Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "import joblib\n",
    "import catboost as cat\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882a75bc",
   "metadata": {},
   "source": [
    "## 2. read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "985ef80e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T08:54:09.396302Z",
     "start_time": "2022-08-08T08:54:07.519016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.5 s, sys: 6.91 s, total: 14.4 s\n",
      "Wall time: 7.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_parquet('/home/featurize/data/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f81aa74-208a-42a0-8c03-7daaf3a0e777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5531451, 190)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92f1cf54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T08:54:11.240922Z",
     "start_time": "2022-08-08T08:54:09.725084Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(\"/home/featurize/work/train_labels.csv\")\n",
    "sub = pd.read_csv('/home/featurize/work/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "401959ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T08:54:12.881542Z",
     "start_time": "2022-08-08T08:54:11.536324Z"
    }
   },
   "outputs": [],
   "source": [
    "features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ef0ad8f-c138-40e3-9250-1bbcb54a10c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\"B_30\",\"B_38\", \"D_114\", \"D_116\", \"D_117\",\"D_120\", \"D_126\", \"D_63\", \"D_64\", \"D_66\", \"D_68\"]\n",
    "num_features = [col for col in features if col not in cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed9d2b5-58fd-426a-8243-305460ad18a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 14.3 s, total: 29.2 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = pd.read_parquet('/home/featurize/data/test.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c9502a",
   "metadata": {},
   "source": [
    "#### 2.1. 测试用例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390bb8b7",
   "metadata": {},
   "source": [
    "租服务器太贵，每次用全量样本运行模型耗时5h+，同时也会面临一些代码层面的错误而浪费一时间。时间就是金钱！！所以我会先写个demo，保证代码层面没错，再来运行全部代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5073e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEMO \n",
    "train = train.loc[0:1000,]\n",
    "test = test.loc[0:1000,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799db59b",
   "metadata": {},
   "source": [
    "## 3. 特征工程及衍生变量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0966aa",
   "metadata": {},
   "source": [
    "### 3.1. 处理时间列\n",
    "\n",
    "在处理的时候写成function，同时处理 train 和test，这样在后续建模中也较为方便。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50488338-39df-430a-960d-70e2382045c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proprocess_time(df):\n",
    "    df['S_2'] = pd.to_datetime(df['S_2'])\n",
    "    df['S_2_dayofweek'] = df['S_2'].dt.weekday\n",
    "    df['S_2_dayofmonth'] = df['S_2'].dt.day\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c8468ef-4dfc-4b83-980e-16d7dfb619a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.45 s, sys: 160 ms, total: 1.61 s\n",
      "Wall time: 1.61 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5531451, 192)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train = proprocess_time(train)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3bd3fc4-f266-4e5d-8b72-e05ca3f474fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.95 s, sys: 337 ms, total: 3.29 s\n",
      "Wall time: 3.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11363762, 192)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test = proprocess_time(test)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3da9c0",
   "metadata": {},
   "source": [
    "###  3.2.处理 numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98d5cc95-0425-4498-9aaa-c4144f2c8dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_numeric(df):\n",
    "    train_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    return train_num_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b46bfdbe-e9ae-45c6-a1dd-e599334a41cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.2 s, sys: 15.5 s, total: 54.8 s\n",
      "Wall time: 55.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_num_agg = preprocess_numeric(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7a7eacc-4c99-4364-b42c-358112bd7cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 20s, sys: 35.5 s, total: 1min 56s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_num_agg = preprocess_numeric(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267cb328",
   "metadata": {},
   "source": [
    "### 3.3.处理 categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49d0585a-b4dc-47ba-bfb0-3a5c8b2e2d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_cat(df):\n",
    "    train_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True) \n",
    "    return train_cat_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a7e9064-00b5-4b15-9e75-a9c6a36e1fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat_agg = preprocess_cat(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb218153-12cf-497f-8953-a537376e4249",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\"B_30\",\"B_38\", \"D_114\", \"D_116\", \"D_117\",\"D_120\", \"D_126\", \"D_63\", \"D_64\", \"D_66\", \"D_68\"]\n",
    "test_cat_agg = preprocess_cat(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cf1c2a",
   "metadata": {},
   "source": [
    "### 3.4. 记录衍生后的特征总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d57fa378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T07:46:18.511215Z",
     "start_time": "2022-08-08T07:46:18.503873Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((458913, 886), (458913, 34))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num_agg.shape,train_cat_agg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4828d108",
   "metadata": {},
   "source": [
    "### 3.5. 数据合并\n",
    "\n",
    "由于我们是分批处理numerical 和 categorical，因此，在入模之前，我们还需对所有的的变量合并，确保数据的完整度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37d0404d-004f-4bd1-956c-3f9879ba7e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(train_num_agg,train_cat_agg):\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc46883f-4fd2-47b4-9351-af535abb7c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 7.08 s, total: 1min 16s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = merge(train_num_agg,train_cat_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8c5e29b-a6c6-416d-b033-c42cb210df42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 9s, sys: 2min 44s, total: 4min 53s\n",
      "Wall time: 4min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = pd.merge(test_num_agg,test_cat_agg, how = 'inner',on = 'customer_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "771fb403-6cb7-4590-a6f7-86c65c37860b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((924621, 886), (924621, 34))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num_agg.shape,test_cat_agg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3915069",
   "metadata": {},
   "source": [
    "**Attention** 运行内存容量有限，随写随删，不然内存耗尽会崩。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f94a39f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T07:50:58.533779Z",
     "start_time": "2022-08-08T07:50:58.527525Z"
    }
   },
   "outputs": [],
   "source": [
    "del train_num_agg, train_cat_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75577bf2-df95-47fc-8010-7bd8f6e7a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_num_agg, test_cat_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b495c-887a-451a-bdbd-2fe3ba349395",
   "metadata": {},
   "source": [
    "### 3.6. categorical features enconding & nemerical features 去噪音化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75541162-5d79-4a12-8caf-734d04316afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_round(df):\n",
    "    cat_features = [\"B_30\",\"B_38\", \"D_114\", \"D_116\", \"D_117\",\"D_120\", \"D_126\", \"D_63\", \"D_64\", \"D_66\", \"D_68\"]\n",
    "    cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "    for cat_col in cat_features:\n",
    "        encoder = LabelEncoder()\n",
    "        df[cat_col] = encoder.fit_transform(df[cat_col])\n",
    "        \n",
    "    num_cols = list(df.dtypes[(df.dtypes == 'float32') | (df.dtypes == 'float64')].index)\n",
    "    num_cols = [col for col in num_cols if 'last' in col]\n",
    "    for col in num_cols:\n",
    "        df[col + '_round2'] = df[col].round(2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fbaaf399-996a-437d-9e16-265cd228ebec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458913, 1013)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trian = encode_round(train)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32d2a871-c17a-4887-8500-1a4a289841e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924621, 1012)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = encode_round(test)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b61dc06-a7c8-4735-b050-1af673e4987c",
   "metadata": {},
   "source": [
    "## 4. 判别方程\n",
    "\n",
    "该部分判断条件由美国运通所决定，因此无需过多浏览，实际业务也并不会使用该类判断。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d145312-37bb-4289-852d-85c030402591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label()), True\n",
    "\n",
    "def xgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "# Created by https://www.kaggle.com/yunchonggan\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "# we still need the official metric since the faster version above is slightly off\n",
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "def amex_metric_mod_lgbm(y_pred: np.ndarray, data: lgb.Dataset):\n",
    "\n",
    "    y_true = data.get_label()\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 'AMEX', 0.5 * (gini[1]/gini[0]+ top_four), True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc00bff8",
   "metadata": {},
   "source": [
    "## 5. 开始建模"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c26bc0-392e-4585-93e8-df88e47157bd",
   "metadata": {},
   "source": [
    "### 5.1.xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "717a217b-8248-4122-bc95-723114791b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_train(x, y, xt, yt):\n",
    "    print(\"-----------xgb starts training-----------\")\n",
    "    print(\"# of features:\", x.shape[1])\n",
    "    assert x.shape[1] == xt.shape[1]\n",
    "    dtrain = xgb.DMatrix(data=x, label=y)\n",
    "    dvalid = xgb.DMatrix(data=xt, label=yt)\n",
    "    params = {\n",
    "            'objective': 'binary:logistic', \n",
    "            'tree_method': 'auto', \n",
    "            'max_depth': 7,\n",
    "            'subsample':0.88,\n",
    "            'colsample_bytree': 0.5,\n",
    "            'gamma':1.5,\n",
    "            'min_child_weight':8,\n",
    "            'lambda':70,\n",
    "            'eta':0.03,\n",
    "#             'scale_pos_weight': scale_pos_weight,\n",
    "    }\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    bst = xgb.train(params, dtrain=dtrain,\n",
    "                num_boost_round=5000,evals=watchlist,\n",
    "                early_stopping_rounds=100, feval=xgb_amex, maximize=True,\n",
    "                verbose_eval=100)\n",
    "    print('best ntree_limit:', bst.best_ntree_limit)\n",
    "    print('best score:', bst.best_score)\n",
    "    return bst.predict(dtrain, iteration_range=(0,bst.best_ntree_limit)), bst.predict(dvalid, iteration_range=(0,bst.best_ntree_limit)), bst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5857b6-cd4e-4873-9440-95d2cea402dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.2. lgbm-gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1b4c145-5243-412e-afc2-ad07d2e44908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_train(x, y, xt, yt):\n",
    "    print(\"----------lgb starts training----------\")\n",
    "    print(\"# of features:\", x.shape[1])\n",
    "    assert x.shape[1] == xt.shape[1]\n",
    "    # lgb_train = lgb.Dataset(x.to_pandas(), y.to_pandas())\n",
    "    # lgb_eval = lgb.Dataset(xt.to_pandas(), yt.to_pandas(), reference=lgb_train)\n",
    "    lgb_train = lgb.Dataset(x, y)\n",
    "    lgb_eval = lgb.Dataset(xt, yt, reference=lgb_train)\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting':'gbdt',\n",
    "        'seed': 42,\n",
    "        'num_leaves': 100,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.20,\n",
    "        'bagging_freq': 10,\n",
    "        'bagging_fraction': 0.50,\n",
    "        'n_jobs': -1,\n",
    "        'lambda_l2': 2,\n",
    "        'min_data_in_leaf': 40\n",
    "       \n",
    "    }\n",
    "    gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=5000,\n",
    "                valid_sets=[lgb_train, lgb_eval],\n",
    "                early_stopping_rounds=100,feval=amex_metric_mod_lgbm, \n",
    "                verbose_eval=100,)\n",
    "\n",
    "\n",
    "    print('best iterations:', gbm.best_iteration)\n",
    "    print('best score:', gbm.best_score)\n",
    "    return gbm.predict(x, num_iteration =gbm.best_iteration),gbm.predict(xt, num_iteration =gbm.best_iteration), gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91b80ba-6110-4ff1-bc9d-ea09bb659509",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.3. catgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f4f1248-f856-4b0a-a04d-1e8508ca4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_train(x, y, xt, yt):\n",
    "    print(\"-----------catboost starts training-----------\")\n",
    "    print(\"# of features:\", x.shape[1])\n",
    "    assert x.shape[1] == xt.shape[1]\n",
    "    cat_train = cat.Pool(x, y)\n",
    "    cat_eval = cat.Pool(xt, yt)\n",
    "    \n",
    "    clf = CatBoostRegressor(iterations=5000, \n",
    "                             task_type='CPU',\n",
    "                             bagging_temperature = 0.2,\n",
    "                             od_type='Iter',\n",
    "                             metric_period = 50,\n",
    "                             od_wait=20)\n",
    "    clf.fit(cat_train, eval_set=cat_eval, verbose=100,early_stopping_rounds=100)\n",
    "    return  clf.predict(cat_eval), clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aa79af",
   "metadata": {},
   "source": [
    "### 5.4. 训练模型\n",
    "\n",
    "由于数据集量极大，因此整个模型过程，该部分耗时最久，普通GPU加载下，还需6h左右。但此处并非决定模型好坏的关键因素。只要特征衍生以及入模数据处理的好，模型效果总不会差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "679d3c34-64e8-4c8b-ac3b-f4585bdbc838",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Folds 0===============\n",
      "-----------xgb starts training-----------\n",
      "# of features: 1011\n",
      "[0]\ttrain-logloss:0.67371\ttrain-amex:0.70659\teval-logloss:0.67380\teval-amex:0.69917\n",
      "[99]\ttrain-logloss:0.24242\ttrain-amex:0.78084\teval-logloss:0.24837\teval-amex:0.76634\n",
      "best ntree_limit: 100\n",
      "best score: 0.766344\n",
      "----------lgb starts training----------\n",
      "# of features: 1011\n",
      "[LightGBM] [Info] Number of positive: 95258, number of negative: 271872\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.688451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163950\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 1003\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259467 -> initscore=-1.048742\n",
      "[LightGBM] [Info] Start training from score -1.048742\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.320411\ttraining's AMEX: 0.772166\tvalid_1's binary_logloss: 0.322061\tvalid_1's AMEX: 0.760757\n",
      "[200]\ttraining's binary_logloss: 0.254833\ttraining's AMEX: 0.783088\tvalid_1's binary_logloss: 0.25946\tvalid_1's AMEX: 0.768247\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.254833\ttraining's AMEX: 0.783088\tvalid_1's binary_logloss: 0.25946\tvalid_1's AMEX: 0.768247\n",
      "best iterations: 200\n",
      "best score: defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('binary_logloss', 0.2548325746587242), ('AMEX', 0.783088455572817)]), 'valid_1': OrderedDict([('binary_logloss', 0.2594599888843262), ('AMEX', 0.7682468562264738)])})\n",
      "-----------catboost starts training-----------\n",
      "# of features: 1011\n",
      "Learning rate set to 0.343514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3662659\ttest: 0.3651642\tbest: 0.3651642 (0)\ttotal: 229ms\tremaining: 45.6s\n",
      "100:\tlearn: 0.2609307\ttest: 0.2666794\tbest: 0.2666794 (100)\ttotal: 14.6s\tremaining: 14.3s\n",
      "199:\tlearn: 0.2549217\ttest: 0.2660373\tbest: 0.2660103 (181)\ttotal: 28.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2660102522\n",
      "bestIteration = 181\n",
      "\n",
      "Shrink model to first 182 iterations.\n",
      "Fold 0 amex 0.7720\n",
      "==============Folds 1===============\n",
      "-----------xgb starts training-----------\n",
      "# of features: 1011\n",
      "[0]\ttrain-logloss:0.67373\ttrain-amex:0.70413\teval-logloss:0.67383\teval-amex:0.69728\n",
      "[99]\ttrain-logloss:0.24209\ttrain-amex:0.78083\teval-logloss:0.24921\teval-amex:0.76798\n",
      "best ntree_limit: 98\n",
      "best score: 0.768142\n",
      "----------lgb starts training----------\n",
      "# of features: 1011\n",
      "[LightGBM] [Info] Number of positive: 95167, number of negative: 271963\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.517507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163932\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 1003\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259219 -> initscore=-1.050033\n",
      "[LightGBM] [Info] Start training from score -1.050033\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.320097\ttraining's AMEX: 0.772471\tvalid_1's binary_logloss: 0.32302\tvalid_1's AMEX: 0.762221\n",
      "[200]\ttraining's binary_logloss: 0.254496\ttraining's AMEX: 0.783447\tvalid_1's binary_logloss: 0.260298\tvalid_1's AMEX: 0.769901\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.254496\ttraining's AMEX: 0.783447\tvalid_1's binary_logloss: 0.260298\tvalid_1's AMEX: 0.769901\n",
      "best iterations: 200\n",
      "best score: defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('binary_logloss', 0.25449641387399324), ('AMEX', 0.7834473968496526)]), 'valid_1': OrderedDict([('binary_logloss', 0.2602982523325933), ('AMEX', 0.7699013788292427)])})\n",
      "-----------catboost starts training-----------\n",
      "# of features: 1011\n",
      "Learning rate set to 0.343514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3656816\ttest: 0.3651761\tbest: 0.3651761 (0)\ttotal: 179ms\tremaining: 35.6s\n",
      "100:\tlearn: 0.2610076\ttest: 0.2663813\tbest: 0.2663813 (100)\ttotal: 14.8s\tremaining: 14.5s\n",
      "199:\tlearn: 0.2548046\ttest: 0.2657349\tbest: 0.2656664 (171)\ttotal: 28.4s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.265666387\n",
      "bestIteration = 171\n",
      "\n",
      "Shrink model to first 172 iterations.\n",
      "Fold 1 amex 0.7738\n",
      "==============Folds 2===============\n",
      "-----------xgb starts training-----------\n",
      "# of features: 1011\n",
      "[0]\ttrain-logloss:0.67373\ttrain-amex:0.71082\teval-logloss:0.67386\teval-amex:0.69898\n",
      "[99]\ttrain-logloss:0.24215\ttrain-amex:0.78214\teval-logloss:0.24937\teval-amex:0.76709\n",
      "best ntree_limit: 100\n",
      "best score: 0.767091\n",
      "----------lgb starts training----------\n",
      "# of features: 1011\n",
      "[LightGBM] [Info] Number of positive: 94985, number of negative: 272145\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.617945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163966\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 1003\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258723 -> initscore=-1.052616\n",
      "[LightGBM] [Info] Start training from score -1.052616\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.319967\ttraining's AMEX: 0.772227\tvalid_1's binary_logloss: 0.323727\tvalid_1's AMEX: 0.761276\n",
      "[200]\ttraining's binary_logloss: 0.254451\ttraining's AMEX: 0.782694\tvalid_1's binary_logloss: 0.260445\tvalid_1's AMEX: 0.769755\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.254451\ttraining's AMEX: 0.782694\tvalid_1's binary_logloss: 0.260445\tvalid_1's AMEX: 0.769755\n",
      "best iterations: 200\n",
      "best score: defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('binary_logloss', 0.2544506083071504), ('AMEX', 0.7826936657739574)]), 'valid_1': OrderedDict([('binary_logloss', 0.26044529384486964), ('AMEX', 0.7697545357080248)])})\n",
      "-----------catboost starts training-----------\n",
      "# of features: 1011\n",
      "Learning rate set to 0.343514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3651172\ttest: 0.3658629\tbest: 0.3658629 (0)\ttotal: 169ms\tremaining: 33.6s\n",
      "100:\tlearn: 0.2611801\ttest: 0.2659755\tbest: 0.2659755 (100)\ttotal: 14.6s\tremaining: 14.4s\n",
      "199:\tlearn: 0.2551166\ttest: 0.2652512\tbest: 0.2651741 (180)\ttotal: 28.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2651741029\n",
      "bestIteration = 180\n",
      "\n",
      "Shrink model to first 181 iterations.\n",
      "Fold 2 amex 0.7747\n",
      "==============Folds 3===============\n",
      "-----------xgb starts training-----------\n",
      "# of features: 1011\n",
      "[0]\ttrain-logloss:0.67372\ttrain-amex:0.70762\teval-logloss:0.67379\teval-amex:0.70326\n",
      "[99]\ttrain-logloss:0.24246\ttrain-amex:0.78028\teval-logloss:0.24842\teval-amex:0.76984\n",
      "best ntree_limit: 99\n",
      "best score: 0.769901\n",
      "----------lgb starts training----------\n",
      "# of features: 1011\n",
      "[LightGBM] [Info] Number of positive: 94856, number of negative: 272275\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.649682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163855\n",
      "[LightGBM] [Info] Number of data points in the train set: 367131, number of used features: 1003\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258371 -> initscore=-1.054453\n",
      "[LightGBM] [Info] Start training from score -1.054453\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.320085\ttraining's AMEX: 0.771319\tvalid_1's binary_logloss: 0.323239\tvalid_1's AMEX: 0.764285\n",
      "[200]\ttraining's binary_logloss: 0.254654\ttraining's AMEX: 0.782036\tvalid_1's binary_logloss: 0.2596\tvalid_1's AMEX: 0.772229\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.254654\ttraining's AMEX: 0.782036\tvalid_1's binary_logloss: 0.2596\tvalid_1's AMEX: 0.772229\n",
      "best iterations: 200\n",
      "best score: defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('binary_logloss', 0.2546535992697292), ('AMEX', 0.7820364827018265)]), 'valid_1': OrderedDict([('binary_logloss', 0.2596004141177936), ('AMEX', 0.7722291517299585)])})\n",
      "-----------catboost starts training-----------\n",
      "# of features: 1011\n",
      "Learning rate set to 0.343514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3649734\ttest: 0.3658084\tbest: 0.3658084 (0)\ttotal: 188ms\tremaining: 37.5s\n",
      "100:\tlearn: 0.2611294\ttest: 0.2659639\tbest: 0.2659576 (99)\ttotal: 14.6s\tremaining: 14.4s\n",
      "199:\tlearn: 0.2550633\ttest: 0.2655921\tbest: 0.2654803 (172)\ttotal: 28.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2654802937\n",
      "bestIteration = 172\n",
      "\n",
      "Shrink model to first 173 iterations.\n",
      "Fold 3 amex 0.7763\n",
      "==============Folds 4===============\n",
      "-----------xgb starts training-----------\n",
      "# of features: 1011\n",
      "[0]\ttrain-logloss:0.67374\ttrain-amex:0.70511\teval-logloss:0.67385\teval-amex:0.69711\n",
      "[99]\ttrain-logloss:0.24223\ttrain-amex:0.78210\teval-logloss:0.24887\teval-amex:0.76612\n",
      "best ntree_limit: 100\n",
      "best score: 0.766116\n",
      "----------lgb starts training----------\n",
      "# of features: 1011\n",
      "[LightGBM] [Info] Number of positive: 95046, number of negative: 272085\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.640122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163930\n",
      "[LightGBM] [Info] Number of data points in the train set: 367131, number of used features: 1003\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258889 -> initscore=-1.051754\n",
      "[LightGBM] [Info] Start training from score -1.051754\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.320083\ttraining's AMEX: 0.772369\tvalid_1's binary_logloss: 0.3233\tvalid_1's AMEX: 0.757894\n",
      "[200]\ttraining's binary_logloss: 0.254506\ttraining's AMEX: 0.782716\tvalid_1's binary_logloss: 0.260302\tvalid_1's AMEX: 0.766838\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.254506\ttraining's AMEX: 0.782716\tvalid_1's binary_logloss: 0.260302\tvalid_1's AMEX: 0.766838\n",
      "best iterations: 200\n",
      "best score: defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('binary_logloss', 0.2545057167643672), ('AMEX', 0.7827155827413421)]), 'valid_1': OrderedDict([('binary_logloss', 0.2603018525453888), ('AMEX', 0.7668381793469532)])})\n",
      "-----------catboost starts training-----------\n",
      "# of features: 1011\n",
      "Learning rate set to 0.343514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3647172\ttest: 0.3648478\tbest: 0.3648478 (0)\ttotal: 164ms\tremaining: 32.6s\n",
      "100:\tlearn: 0.2610071\ttest: 0.2662727\tbest: 0.2662727 (100)\ttotal: 14.7s\tremaining: 14.4s\n",
      "199:\tlearn: 0.2550472\ttest: 0.2656445\tbest: 0.2655963 (167)\ttotal: 28.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2655963142\n",
      "bestIteration = 167\n",
      "\n",
      "Shrink model to first 168 iterations.\n",
      "Fold 4 amex 0.7722\n",
      "Average amex score: 0.7738\n",
      "CPU times: user 5h 51min 52s, sys: 1min 9s, total: 5h 53min 1s\n",
      "Wall time: 34min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "not_used = ['customer_ID','target']\n",
    "not_used = [i for i in not_used if i in train.columns]\n",
    "msgs = {}\n",
    "folds = 5\n",
    "score = 0\n",
    "\n",
    "\n",
    "for i in range(folds):\n",
    "    print(f\"==============Folds {i}===============\")\n",
    "    mask = train['cid']%folds == i\n",
    "    tr,va = train[~mask], train[mask]\n",
    "\n",
    "    x, y = tr.drop(not_used, axis=1), tr['target']\n",
    "    xt, yt = va.drop(not_used, axis=1), va['target']\n",
    "    features = len(x.columns)\n",
    "    \n",
    "    xp, yp, bst = xgb_train(x, y, xt, yt)\n",
    "    bst.save_model(f'models/xgb_{i}.json')\n",
    "\n",
    "    x = tr.drop(not_used, axis=1)\n",
    "    xt = va.drop(not_used, axis=1)\n",
    "    \n",
    "    xp2,yp2,gbm = lgb_train(x, y, xt, yt)\n",
    "    gbm.save_model(f'models/lgb_{i}.json')\n",
    "    \n",
    "    yp3,cats = cat_train(x, y, xt, yt)\n",
    "    cats.save_model(f'models/cat_{i}.json')\n",
    "\n",
    "    preds = yp * 0.35+yp2 * 0.45\n",
    "    amex_score = amex_metric(pd.DataFrame({'target':yt.values}), \n",
    "                                    pd.DataFrame({'prediction':preds}))\n",
    "    msg = f\"Fold {i} amex {amex_score:.4f}\"\n",
    "    print(msg)\n",
    "    score += amex_score\n",
    "    del tr,va,x,y\n",
    "    del xt,yt,cats,gbm\n",
    "    _ = gc.collect()\n",
    "score /= folds\n",
    "print(f\"Average amex score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d5c915",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.3.预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "320dc003-b988-4afb-96d4-99745a53751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yps = []\n",
    "preds = 0\n",
    "folds = 5\n",
    "not_used = ['customer_ID']\n",
    "for i in range(folds):\n",
    "    bst = xgb.Booster()\n",
    "    bst.load_model(f'models/xgb_{i}.json')\n",
    "    dx = xgb.DMatrix(test.drop(not_used,axis =1))\n",
    "    \n",
    "    gbm = lgb.Booster(model_file = f'models/lgb_{i}.json')\n",
    "    dx2 = test.drop(not_used,axis = 1)\n",
    "    \n",
    "    cats = CatBoostRegressor()\n",
    "    cats.load_model(f'models/cat_{i}.json')\n",
    "    \n",
    "    yp = bst.predict(dx,iteration_range = (0,bst.best_ntree_limit))\n",
    "    yp2 = gbm.predict(dx2,num_iteration = gbm.best_iteration)\n",
    "    yp3 = cats.predict(dx2)\n",
    "    \n",
    "    preds += (yp*0.35 + yp2*0.45 + yp3 * 0.25)\n",
    "yps.append(preds/folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3d0af86-2e00-4841-b5c3-60d413e84792",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['prediction'] = yps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe2479-b30d-4d3f-b640-c5381a5adde3",
   "metadata": {},
   "source": [
    "## 6. 结果输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b701c8bb-776f-4751-8dc1-0f1f54a90582",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2ec624c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T09:13:32.885721Z",
     "start_time": "2022-08-08T09:13:28.058385Z"
    }
   },
   "outputs": [],
   "source": [
    "df_submit.to_csv(\"/home/featurize/work/submission_3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "55fd5ada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T09:10:10.273839Z",
     "start_time": "2022-08-08T09:09:13.767397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>0.028926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...</td>\n",
       "      <td>0.000817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...</td>\n",
       "      <td>0.052601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...</td>\n",
       "      <td>0.246161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...</td>\n",
       "      <td>0.841315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924616</th>\n",
       "      <td>ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c...</td>\n",
       "      <td>0.017092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924617</th>\n",
       "      <td>ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3...</td>\n",
       "      <td>0.785878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924618</th>\n",
       "      <td>ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475...</td>\n",
       "      <td>0.359771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924619</th>\n",
       "      <td>ffffddef1fc3643ea179c93245b68dca0f36941cd83977...</td>\n",
       "      <td>0.233254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924620</th>\n",
       "      <td>fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...</td>\n",
       "      <td>0.049952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924621 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_ID  prediction\n",
       "0       00000469ba478561f23a92a868bd366de6f6527a684c9a...    0.028926\n",
       "1       00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...    0.000817\n",
       "2       0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...    0.052601\n",
       "3       00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...    0.246161\n",
       "4       00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...    0.841315\n",
       "...                                                   ...         ...\n",
       "924616  ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c...    0.017092\n",
       "924617  ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3...    0.785878\n",
       "924618  ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475...    0.359771\n",
       "924619  ffffddef1fc3643ea179c93245b68dca0f36941cd83977...    0.233254\n",
       "924620  fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...    0.049952\n",
       "\n",
       "[924621 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.read_csv('/home/featurize/work/submission_3.csv')\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cdf763",
   "metadata": {},
   "source": [
    "## 7. 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29747378",
   "metadata": {},
   "source": [
    "该代码简单介绍了整体分类预测模型如何开始与收尾。当然如果想要效果达到非常好的程度，还有很多关键事情可以做。例如特征衍生量是否可以增加，数据去噪是否可以完善，融合模型是否可以有更多的选择，以及融合模型时更多权重的选择。在关于该代码的说明文档中，也会有我关于该竞赛的反思和思考，大家有兴趣可以观看。这份代码仅作为当初我提交的一个版本，还有诸多版本就不一一上传（其余版本在租用服务器平台，早已欠费呜呜呜）就不一一展示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f787f690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
